{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import mnist\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch.nn.functional as TF\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "test_transform = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "\n",
    "train_batch_size = 512\n",
    "val_batch_size = 300\n",
    "test_batch_size = 100\n",
    "train_dataset = mnist.MNIST(root='data/MNIST/train', train=True,\n",
    "                              download=True,transform=transform)\n",
    "test_dataset = mnist.MNIST(root='data/MNIST/test', train=False,\n",
    "                             download=True, transform=test_transform)\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, idx:0, loss:2.303470\n",
      "Epoch:0, idx:50, loss:1.664604\n",
      "Epoch:0, idx:100, loss:0.609361\n",
      "Validation accuracy: 84.1500\n",
      "Epoch:1, idx:0, loss:0.607857\n",
      "Epoch:1, idx:50, loss:0.399100\n",
      "Epoch:1, idx:100, loss:0.390668\n",
      "Validation accuracy: 89.9667\n",
      "Epoch:2, idx:0, loss:0.329201\n",
      "Epoch:2, idx:50, loss:0.294618\n",
      "Epoch:2, idx:100, loss:0.319652\n",
      "Validation accuracy: 91.4500\n",
      "Epoch:3, idx:0, loss:0.274068\n",
      "Epoch:3, idx:50, loss:0.250187\n",
      "Epoch:3, idx:100, loss:0.165481\n",
      "Validation accuracy: 93.1333\n",
      "Epoch:4, idx:0, loss:0.243066\n",
      "Epoch:4, idx:50, loss:0.211686\n",
      "Epoch:4, idx:100, loss:0.168831\n",
      "Validation accuracy: 94.5833\n",
      "Epoch:5, idx:0, loss:0.166868\n",
      "Epoch:5, idx:50, loss:0.200319\n",
      "Epoch:5, idx:100, loss:0.198834\n",
      "Validation accuracy: 95.4333\n",
      "Epoch:6, idx:0, loss:0.118862\n",
      "Epoch:6, idx:50, loss:0.152230\n",
      "Epoch:6, idx:100, loss:0.104994\n",
      "Validation accuracy: 96.2500\n",
      "Epoch:7, idx:0, loss:0.116940\n",
      "Epoch:7, idx:50, loss:0.140235\n",
      "Epoch:7, idx:100, loss:0.125654\n",
      "Validation accuracy: 96.6167\n",
      "Epoch:8, idx:0, loss:0.143528\n",
      "Epoch:8, idx:50, loss:0.099971\n",
      "Epoch:8, idx:100, loss:0.100451\n",
      "Validation accuracy: 97.1167\n",
      "Epoch:9, idx:0, loss:0.097270\n",
      "Epoch:9, idx:50, loss:0.111420\n",
      "Epoch:9, idx:100, loss:0.110200\n",
      "Validation accuracy: 97.3000\n",
      "Epoch:10, idx:0, loss:0.112856\n",
      "Epoch:10, idx:50, loss:0.101289\n",
      "Epoch:10, idx:100, loss:0.089329\n",
      "Validation accuracy: 97.3667\n",
      "Epoch:11, idx:0, loss:0.063605\n",
      "Epoch:11, idx:50, loss:0.090648\n",
      "Epoch:11, idx:100, loss:0.067242\n",
      "Validation accuracy: 97.6333\n",
      "Epoch:12, idx:0, loss:0.066540\n",
      "Epoch:12, idx:50, loss:0.056162\n",
      "Epoch:12, idx:100, loss:0.074730\n",
      "Validation accuracy: 97.9000\n",
      "Epoch:13, idx:0, loss:0.086426\n",
      "Epoch:13, idx:50, loss:0.066457\n",
      "Epoch:13, idx:100, loss:0.051618\n",
      "Validation accuracy: 98.0333\n",
      "Epoch:14, idx:0, loss:0.061173\n",
      "Epoch:14, idx:50, loss:0.051474\n",
      "Epoch:14, idx:100, loss:0.052414\n",
      "Validation accuracy: 98.1000\n",
      "Epoch:15, idx:0, loss:0.059236\n",
      "Epoch:15, idx:50, loss:0.078785\n",
      "Epoch:15, idx:100, loss:0.052164\n",
      "Validation accuracy: 98.2167\n",
      "Epoch:16, idx:0, loss:0.039055\n",
      "Epoch:16, idx:50, loss:0.061335\n",
      "Epoch:16, idx:100, loss:0.050279\n",
      "Validation accuracy: 98.3000\n",
      "Epoch:17, idx:0, loss:0.043735\n",
      "Epoch:17, idx:50, loss:0.035427\n",
      "Epoch:17, idx:100, loss:0.045530\n",
      "Validation accuracy: 98.2667\n",
      "Epoch:18, idx:0, loss:0.058046\n",
      "Epoch:18, idx:50, loss:0.060837\n",
      "Epoch:18, idx:100, loss:0.059926\n",
      "Validation accuracy: 98.4500\n",
      "Epoch:19, idx:0, loss:0.043644\n",
      "Epoch:19, idx:50, loss:0.053739\n",
      "Epoch:19, idx:100, loss:0.049826\n",
      "Validation accuracy: 98.5333\n",
      "Epoch:0, idx:0, loss:2.309177\n",
      "Epoch:0, idx:50, loss:1.496363\n",
      "Epoch:0, idx:100, loss:0.620167\n",
      "Validation accuracy: 86.0000\n",
      "Epoch:1, idx:0, loss:0.557978\n",
      "Epoch:1, idx:50, loss:0.423681\n",
      "Epoch:1, idx:100, loss:0.360754\n",
      "Validation accuracy: 90.7667\n",
      "Epoch:2, idx:0, loss:0.354561\n",
      "Epoch:2, idx:50, loss:0.304397\n",
      "Epoch:2, idx:100, loss:0.276452\n",
      "Validation accuracy: 92.0500\n",
      "Epoch:3, idx:0, loss:0.279230\n",
      "Epoch:3, idx:50, loss:0.241947\n",
      "Epoch:3, idx:100, loss:0.175734\n",
      "Validation accuracy: 93.5667\n",
      "Epoch:4, idx:0, loss:0.264547\n",
      "Epoch:4, idx:50, loss:0.184567\n",
      "Epoch:4, idx:100, loss:0.141361\n",
      "Validation accuracy: 94.6500\n",
      "Epoch:5, idx:0, loss:0.197188\n",
      "Epoch:5, idx:50, loss:0.220702\n",
      "Epoch:5, idx:100, loss:0.146868\n",
      "Validation accuracy: 95.5833\n",
      "Epoch:6, idx:0, loss:0.157411\n",
      "Epoch:6, idx:50, loss:0.149739\n",
      "Epoch:6, idx:100, loss:0.141182\n",
      "Validation accuracy: 95.9000\n",
      "Epoch:7, idx:0, loss:0.163153\n",
      "Epoch:7, idx:50, loss:0.121440\n",
      "Epoch:7, idx:100, loss:0.134651\n",
      "Validation accuracy: 96.3500\n",
      "Epoch:8, idx:0, loss:0.102327\n",
      "Epoch:8, idx:50, loss:0.156436\n",
      "Epoch:8, idx:100, loss:0.081670\n",
      "Validation accuracy: 96.6667\n",
      "Epoch:9, idx:0, loss:0.088148\n",
      "Epoch:9, idx:50, loss:0.103908\n",
      "Epoch:9, idx:100, loss:0.101825\n",
      "Validation accuracy: 96.9833\n",
      "Epoch:10, idx:0, loss:0.108789\n",
      "Epoch:10, idx:50, loss:0.085917\n",
      "Epoch:10, idx:100, loss:0.092908\n",
      "Validation accuracy: 97.2667\n",
      "Epoch:11, idx:0, loss:0.090738\n",
      "Epoch:11, idx:50, loss:0.086957\n",
      "Epoch:11, idx:100, loss:0.039508\n",
      "Validation accuracy: 97.3833\n",
      "Epoch:12, idx:0, loss:0.079859\n",
      "Epoch:12, idx:50, loss:0.067986\n",
      "Epoch:12, idx:100, loss:0.055523\n",
      "Validation accuracy: 97.6333\n",
      "Epoch:13, idx:0, loss:0.067545\n",
      "Epoch:13, idx:50, loss:0.072591\n",
      "Epoch:13, idx:100, loss:0.082095\n",
      "Validation accuracy: 97.6667\n",
      "Epoch:14, idx:0, loss:0.072158\n",
      "Epoch:14, idx:50, loss:0.074900\n",
      "Epoch:14, idx:100, loss:0.089178\n",
      "Validation accuracy: 97.7833\n",
      "Epoch:15, idx:0, loss:0.086819\n",
      "Epoch:15, idx:50, loss:0.053148\n",
      "Epoch:15, idx:100, loss:0.080949\n",
      "Validation accuracy: 97.9167\n",
      "Epoch:16, idx:0, loss:0.078166\n",
      "Epoch:16, idx:50, loss:0.064043\n",
      "Epoch:16, idx:100, loss:0.070088\n",
      "Validation accuracy: 97.9333\n",
      "Epoch:17, idx:0, loss:0.053060\n",
      "Epoch:17, idx:50, loss:0.047364\n",
      "Epoch:17, idx:100, loss:0.044128\n",
      "Validation accuracy: 97.9333\n",
      "Epoch:18, idx:0, loss:0.043027\n",
      "Epoch:18, idx:50, loss:0.043172\n",
      "Epoch:18, idx:100, loss:0.040011\n",
      "Validation accuracy: 98.1167\n",
      "Epoch:19, idx:0, loss:0.053047\n",
      "Epoch:19, idx:50, loss:0.070972\n",
      "Epoch:19, idx:100, loss:0.064206\n",
      "Validation accuracy: 98.0833\n",
      "Epoch:0, idx:0, loss:2.308832\n",
      "Epoch:0, idx:50, loss:1.663242\n",
      "Epoch:0, idx:100, loss:0.651261\n",
      "Validation accuracy: 84.4833\n",
      "Epoch:1, idx:0, loss:0.633991\n",
      "Epoch:1, idx:50, loss:0.448674\n",
      "Epoch:1, idx:100, loss:0.344661\n",
      "Validation accuracy: 89.9500\n",
      "Epoch:2, idx:0, loss:0.330690\n",
      "Epoch:2, idx:50, loss:0.401455\n",
      "Epoch:2, idx:100, loss:0.266264\n",
      "Validation accuracy: 91.7000\n",
      "Epoch:3, idx:0, loss:0.242252\n",
      "Epoch:3, idx:50, loss:0.225022\n",
      "Epoch:3, idx:100, loss:0.202874\n",
      "Validation accuracy: 93.1500\n",
      "Epoch:4, idx:0, loss:0.267513\n",
      "Epoch:4, idx:50, loss:0.176689\n",
      "Epoch:4, idx:100, loss:0.190240\n",
      "Validation accuracy: 94.0833\n",
      "Epoch:5, idx:0, loss:0.163138\n",
      "Epoch:5, idx:50, loss:0.154139\n",
      "Epoch:5, idx:100, loss:0.163197\n",
      "Validation accuracy: 95.0333\n",
      "Epoch:6, idx:0, loss:0.206215\n",
      "Epoch:6, idx:50, loss:0.158457\n",
      "Epoch:6, idx:100, loss:0.134823\n",
      "Validation accuracy: 95.5667\n",
      "Epoch:7, idx:0, loss:0.111802\n",
      "Epoch:7, idx:50, loss:0.091867\n",
      "Epoch:7, idx:100, loss:0.211938\n",
      "Validation accuracy: 96.3500\n",
      "Epoch:8, idx:0, loss:0.141406\n",
      "Epoch:8, idx:50, loss:0.098566\n",
      "Epoch:8, idx:100, loss:0.073194\n",
      "Validation accuracy: 96.6833\n",
      "Epoch:9, idx:0, loss:0.099453\n",
      "Epoch:9, idx:50, loss:0.143086\n",
      "Epoch:9, idx:100, loss:0.086638\n",
      "Validation accuracy: 97.0167\n",
      "Epoch:10, idx:0, loss:0.066044\n",
      "Epoch:10, idx:50, loss:0.091955\n",
      "Epoch:10, idx:100, loss:0.104853\n",
      "Validation accuracy: 97.2000\n",
      "Epoch:11, idx:0, loss:0.064259\n",
      "Epoch:11, idx:50, loss:0.074543\n",
      "Epoch:11, idx:100, loss:0.081457\n",
      "Validation accuracy: 97.4833\n",
      "Epoch:12, idx:0, loss:0.078745\n",
      "Epoch:12, idx:50, loss:0.059979\n",
      "Epoch:12, idx:100, loss:0.083681\n",
      "Validation accuracy: 97.4667\n",
      "Epoch:13, idx:0, loss:0.076640\n",
      "Epoch:13, idx:50, loss:0.064028\n",
      "Epoch:13, idx:100, loss:0.064815\n",
      "Validation accuracy: 97.5833\n",
      "Epoch:14, idx:0, loss:0.086981\n",
      "Epoch:14, idx:50, loss:0.074210\n",
      "Epoch:14, idx:100, loss:0.109831\n",
      "Validation accuracy: 97.6833\n",
      "Epoch:15, idx:0, loss:0.062181\n",
      "Epoch:15, idx:50, loss:0.056295\n",
      "Epoch:15, idx:100, loss:0.070668\n",
      "Validation accuracy: 97.8000\n",
      "Epoch:16, idx:0, loss:0.061285\n",
      "Epoch:16, idx:50, loss:0.069525\n",
      "Epoch:16, idx:100, loss:0.056944\n",
      "Validation accuracy: 97.8333\n",
      "Epoch:17, idx:0, loss:0.068096\n",
      "Epoch:17, idx:50, loss:0.041465\n",
      "Epoch:17, idx:100, loss:0.048772\n",
      "Validation accuracy: 97.8667\n",
      "Epoch:18, idx:0, loss:0.076320\n",
      "Epoch:18, idx:50, loss:0.048673\n",
      "Epoch:18, idx:100, loss:0.049807\n",
      "Validation accuracy: 98.0500\n",
      "Epoch:19, idx:0, loss:0.051806\n",
      "Epoch:19, idx:50, loss:0.047481\n",
      "Epoch:19, idx:100, loss:0.050713\n",
      "Validation accuracy: 98.0667\n",
      "Epoch:0, idx:0, loss:2.304408\n",
      "Epoch:0, idx:50, loss:1.647532\n",
      "Epoch:0, idx:100, loss:0.718651\n",
      "Validation accuracy: 82.4167\n",
      "Epoch:1, idx:0, loss:0.672192\n",
      "Epoch:1, idx:50, loss:0.433485\n",
      "Epoch:1, idx:100, loss:0.374115\n",
      "Validation accuracy: 89.9500\n",
      "Epoch:2, idx:0, loss:0.363453\n",
      "Epoch:2, idx:50, loss:0.331586\n",
      "Epoch:2, idx:100, loss:0.268476\n",
      "Validation accuracy: 91.4667\n",
      "Epoch:3, idx:0, loss:0.282879\n",
      "Epoch:3, idx:50, loss:0.255204\n",
      "Epoch:3, idx:100, loss:0.233742\n",
      "Validation accuracy: 92.9667\n",
      "Epoch:4, idx:0, loss:0.254792\n",
      "Epoch:4, idx:50, loss:0.251648\n",
      "Epoch:4, idx:100, loss:0.203929\n",
      "Validation accuracy: 94.2333\n",
      "Epoch:5, idx:0, loss:0.199924\n",
      "Epoch:5, idx:50, loss:0.204911\n",
      "Epoch:5, idx:100, loss:0.168906\n",
      "Validation accuracy: 94.8833\n",
      "Epoch:6, idx:0, loss:0.152094\n",
      "Epoch:6, idx:50, loss:0.142656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, idx:100, loss:0.129866\n",
      "Validation accuracy: 95.5000\n",
      "Epoch:7, idx:0, loss:0.117183\n",
      "Epoch:7, idx:50, loss:0.130889\n",
      "Epoch:7, idx:100, loss:0.122367\n",
      "Validation accuracy: 95.8667\n",
      "Epoch:8, idx:0, loss:0.178375\n",
      "Epoch:8, idx:50, loss:0.128246\n",
      "Epoch:8, idx:100, loss:0.139144\n",
      "Validation accuracy: 96.3000\n",
      "Epoch:9, idx:0, loss:0.094556\n",
      "Epoch:9, idx:50, loss:0.091627\n",
      "Epoch:9, idx:100, loss:0.103609\n",
      "Validation accuracy: 96.6500\n",
      "Epoch:10, idx:0, loss:0.084793\n",
      "Epoch:10, idx:50, loss:0.089521\n",
      "Epoch:10, idx:100, loss:0.065698\n",
      "Validation accuracy: 96.8667\n",
      "Epoch:11, idx:0, loss:0.090284\n",
      "Epoch:11, idx:50, loss:0.068910\n",
      "Epoch:11, idx:100, loss:0.088452\n",
      "Validation accuracy: 97.1667\n",
      "Epoch:12, idx:0, loss:0.072731\n",
      "Epoch:12, idx:50, loss:0.060135\n",
      "Epoch:12, idx:100, loss:0.085572\n",
      "Validation accuracy: 97.2833\n",
      "Epoch:13, idx:0, loss:0.116088\n",
      "Epoch:13, idx:50, loss:0.081193\n",
      "Epoch:13, idx:100, loss:0.074829\n",
      "Validation accuracy: 97.4167\n",
      "Epoch:14, idx:0, loss:0.069160\n",
      "Epoch:14, idx:50, loss:0.053970\n",
      "Epoch:14, idx:100, loss:0.090881\n",
      "Validation accuracy: 97.4833\n",
      "Epoch:15, idx:0, loss:0.082311\n",
      "Epoch:15, idx:50, loss:0.079030\n",
      "Epoch:15, idx:100, loss:0.063991\n",
      "Validation accuracy: 97.5500\n",
      "Epoch:16, idx:0, loss:0.055697\n",
      "Epoch:16, idx:50, loss:0.050261\n",
      "Epoch:16, idx:100, loss:0.061781\n",
      "Validation accuracy: 97.7167\n",
      "Epoch:17, idx:0, loss:0.044009\n",
      "Epoch:17, idx:50, loss:0.050482\n",
      "Epoch:17, idx:100, loss:0.050649\n",
      "Validation accuracy: 97.7833\n",
      "Epoch:18, idx:0, loss:0.074264\n",
      "Epoch:18, idx:50, loss:0.034361\n",
      "Epoch:18, idx:100, loss:0.062018\n",
      "Validation accuracy: 97.7667\n",
      "Epoch:19, idx:0, loss:0.041323\n",
      "Epoch:19, idx:50, loss:0.046211\n",
      "Epoch:19, idx:100, loss:0.057906\n",
      "Validation accuracy: 97.8333\n",
      "Epoch:0, idx:0, loss:2.305065\n",
      "Epoch:0, idx:50, loss:1.418391\n",
      "Epoch:0, idx:100, loss:0.587578\n",
      "Validation accuracy: 85.2333\n",
      "Epoch:1, idx:0, loss:0.573361\n",
      "Epoch:1, idx:50, loss:0.469447\n",
      "Epoch:1, idx:100, loss:0.289854\n",
      "Validation accuracy: 90.2167\n",
      "Epoch:2, idx:0, loss:0.322997\n",
      "Epoch:2, idx:50, loss:0.331003\n",
      "Epoch:2, idx:100, loss:0.305772\n",
      "Validation accuracy: 92.1500\n",
      "Epoch:3, idx:0, loss:0.271072\n",
      "Epoch:3, idx:50, loss:0.199238\n",
      "Epoch:3, idx:100, loss:0.230566\n",
      "Validation accuracy: 93.1667\n",
      "Epoch:4, idx:0, loss:0.194913\n",
      "Epoch:4, idx:50, loss:0.179534\n",
      "Epoch:4, idx:100, loss:0.164811\n",
      "Validation accuracy: 94.2667\n",
      "Epoch:5, idx:0, loss:0.170164\n",
      "Epoch:5, idx:50, loss:0.144088\n",
      "Epoch:5, idx:100, loss:0.186196\n",
      "Validation accuracy: 95.3167\n",
      "Epoch:6, idx:0, loss:0.125084\n",
      "Epoch:6, idx:50, loss:0.150746\n",
      "Epoch:6, idx:100, loss:0.116180\n",
      "Validation accuracy: 95.8333\n",
      "Epoch:7, idx:0, loss:0.127925\n",
      "Epoch:7, idx:50, loss:0.141418\n",
      "Epoch:7, idx:100, loss:0.112615\n",
      "Validation accuracy: 96.4667\n",
      "Epoch:8, idx:0, loss:0.101750\n",
      "Epoch:8, idx:50, loss:0.101226\n",
      "Epoch:8, idx:100, loss:0.115742\n",
      "Validation accuracy: 96.7167\n",
      "Epoch:9, idx:0, loss:0.085950\n",
      "Epoch:9, idx:50, loss:0.076588\n",
      "Epoch:9, idx:100, loss:0.067478\n",
      "Validation accuracy: 97.0833\n",
      "Epoch:10, idx:0, loss:0.072450\n",
      "Epoch:10, idx:50, loss:0.094426\n",
      "Epoch:10, idx:100, loss:0.080697\n",
      "Validation accuracy: 97.1667\n",
      "Epoch:11, idx:0, loss:0.084901\n",
      "Epoch:11, idx:50, loss:0.084308\n",
      "Epoch:11, idx:100, loss:0.098354\n",
      "Validation accuracy: 97.5833\n",
      "Epoch:12, idx:0, loss:0.061866\n",
      "Epoch:12, idx:50, loss:0.077609\n",
      "Epoch:12, idx:100, loss:0.096247\n",
      "Validation accuracy: 97.6500\n",
      "Epoch:13, idx:0, loss:0.076539\n",
      "Epoch:13, idx:50, loss:0.080924\n",
      "Epoch:13, idx:100, loss:0.071094\n",
      "Validation accuracy: 97.7167\n",
      "Epoch:14, idx:0, loss:0.051018\n",
      "Epoch:14, idx:50, loss:0.059646\n",
      "Epoch:14, idx:100, loss:0.059434\n",
      "Validation accuracy: 97.9167\n",
      "Epoch:15, idx:0, loss:0.056629\n",
      "Epoch:15, idx:50, loss:0.046528\n",
      "Epoch:15, idx:100, loss:0.052497\n",
      "Validation accuracy: 97.9833\n",
      "Epoch:16, idx:0, loss:0.054194\n",
      "Epoch:16, idx:50, loss:0.059978\n",
      "Epoch:16, idx:100, loss:0.041907\n",
      "Validation accuracy: 98.0500\n",
      "Epoch:17, idx:0, loss:0.043215\n",
      "Epoch:17, idx:50, loss:0.066195\n",
      "Epoch:17, idx:100, loss:0.046537\n",
      "Validation accuracy: 98.2000\n",
      "Epoch:18, idx:0, loss:0.065118\n",
      "Epoch:18, idx:50, loss:0.053499\n",
      "Epoch:18, idx:100, loss:0.061191\n",
      "Validation accuracy: 98.3000\n",
      "Epoch:19, idx:0, loss:0.075376\n",
      "Epoch:19, idx:50, loss:0.040511\n",
      "Epoch:19, idx:100, loss:0.047465\n",
      "Validation accuracy: 98.4500\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = 'Logs/'\n",
    "SAVE_DIR = 'Models/'\n",
    "\n",
    "for SEED in range(5):\n",
    "    torch.manual_seed(SEED)\n",
    "    train, val = random_split(train_dataset,[int(0.9*len(train_dataset)),int(0.1*len(train_dataset))])\n",
    "    \n",
    "#     all_index = np.arange(len(train_dataset))\n",
    "#     np.random.shuffle(all_index)\n",
    "#     train_index = all_index[0:int(0.9*len(train_dataset))]\n",
    "#     val_index = all_index[int(0.9*len(train_dataset)):]\n",
    "    \n",
    "    train_loader = DataLoader(train, shuffle=True, batch_size=train_batch_size)\n",
    "    val_loader = DataLoader(val, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "\n",
    "    model = LeNet5().double().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    cost = nn.CrossEntropyLoss()\n",
    "    epoch = 20\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    LEARN_SEED = 42\n",
    "    torch.manual_seed(LEARN_SEED)\n",
    "    best_val_acc = 0.0\n",
    "    for _epoch in range(epoch):\n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "            train_x, train_label = train_x.double().to(device), train_label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_x)\n",
    "            loss = cost(outputs, train_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if idx % 50 == 0:\n",
    "                print('Epoch:%d, idx:%d, loss:%.6f'%(_epoch, idx, loss.sum().item()))\n",
    "            train_loss.append(loss.sum().item())\n",
    "\n",
    "        correct = 0\n",
    "        _sum = 0\n",
    "\n",
    "        for idx, (val_x, val_label) in enumerate(val_loader):\n",
    "            val_x, val_label = val_x.double().to(device), val_label.to(device)\n",
    "            outputs = model(val_x).detach()\n",
    "            t_loss = cost(outputs, val_label)\n",
    "            predict_ys = torch.argmax(outputs, axis=-1)\n",
    "            _ = predict_ys.detach().data == val_label\n",
    "            correct += torch.sum(_, axis=-1)\n",
    "            _sum += _.shape[0]\n",
    "            val_loss.append(t_loss.sum().item())\n",
    "        val_acc = 100*correct / _sum\n",
    "        print('Validation accuracy: %.4f'%val_acc)\n",
    "    \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_ckpt = {'net':model.state_dict(),\n",
    "                        'optim':optimizer.state_dict(),\n",
    "                        'epoch':_epoch,\n",
    "                        'val_acc':best_val_acc}\n",
    "            best_save_path = SAVE_DIR + \"MNIST_CNN_Val_SEED_%d_model\"%SEED\n",
    "            torch.save(best_ckpt, best_save_path)\n",
    "            \n",
    "    log_save_path = LOG_DIR + \"MNIST_CNN_Val_SEED_%d_log\"%SEED\n",
    "\n",
    "    pickle.dump([train_loss, val_loss], open(log_save_path,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(98.5333, device='cuda:0')\n",
      "tensor(98.1167, device='cuda:0')\n",
      "tensor(98.0667, device='cuda:0')\n",
      "tensor(97.8333, device='cuda:0')\n",
      "tensor(98.4500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for SEED in range(5):\n",
    "    best_save_path = SAVE_DIR + \"MNIST_CNN_Val_SEED_%d_model\"%SEED\n",
    "    print(torch.load(best_save_path)['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9853333333333333\n",
      "[0.99078341 0.99157088 0.98426573 0.97807757 0.98572628 0.98217469\n",
      " 0.99268887 0.98621249 0.97757848 0.98206661]\n",
      "[0.99990411 0.99995074 0.99985258 0.99970153 0.99949382 0.99977813\n",
      " 0.99997487 0.99989972 0.99971396 0.99977597]\n",
      "0.9811666666666666\n",
      "[0.98657718 0.98302583 0.98623064 0.98204668 0.98109966 0.97798165\n",
      " 0.98913952 0.98057498 0.98260149 0.96266234]\n",
      "[0.99988312 0.99988665 0.99990359 0.99936676 0.999822   0.99962842\n",
      " 0.99992579 0.99981884 0.99981663 0.99906824]\n",
      "0.9806666666666667\n",
      "[0.98181818 0.99303944 0.9798995  0.97072419 0.9844898  0.98314108\n",
      " 0.98836168 0.97848606 0.97670406 0.97026338]\n",
      "[0.99984604 0.99981402 0.99983228 0.9983117  0.99944572 0.99847921\n",
      " 0.99982612 0.99952137 0.9996972  0.99873196]\n",
      "0.9783333333333334\n",
      "[0.98537477 0.98459281 0.97978981 0.97838271 0.9788315  0.98084291\n",
      " 0.98328936 0.97709924 0.96611642 0.96920583]\n",
      "[0.99983525 0.99982354 0.99985391 0.99979578 0.99827092 0.99945016\n",
      " 0.99952999 0.99967708 0.99960317 0.99888389]\n",
      "0.9845\n",
      "[0.98848684 0.98566038 0.98212766 0.98223938 0.98694517 0.98865784\n",
      " 0.98540773 0.98656126 0.97914929 0.98005204]\n",
      "[0.99987885 0.99986314 0.99986595 0.99905011 0.99994165 0.99984363\n",
      " 0.99987619 0.99976968 0.9995408  0.99869694]\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'Models/'\n",
    "for SEED in range(5):\n",
    "    torch.manual_seed(SEED)\n",
    "    train, val = random_split(train_dataset,[int(0.9*len(train_dataset)),int(0.1*len(train_dataset))])\n",
    "    \n",
    "    train_loader = DataLoader(train, shuffle=True, batch_size=train_batch_size)\n",
    "    val_loader = DataLoader(val, shuffle=True, batch_size=val_batch_size)\n",
    "    \n",
    "    best_save_path = SAVE_DIR + \"MNIST_CNN_Val_SEED_%d_model\"%SEED\n",
    "    model = LeNet5().double().to(device)\n",
    "    model.load_state_dict(torch.load(best_save_path)['net'])\n",
    "    \n",
    "    y_vals = []\n",
    "    y_vals_onehot = []\n",
    "    y_outputs = []\n",
    "    y_preds = []\n",
    "    for idx, (val_x, val_label) in enumerate(val_loader):\n",
    "        val_x, val_label = val_x.double().to(device), val_label.to(device)\n",
    "        y_vals.append(val_label.cpu().data)\n",
    "        y_vals_onehot.append(TF.one_hot(val_label.cpu().data,10).numpy())\n",
    "        outputs = model(val_x).detach()\n",
    "        y_output = TF.softmax(outputs,-1)\n",
    "        y_outputs.append(y_output.detach().cpu().data.numpy())\n",
    "        y_pred = torch.argmax(outputs, axis=-1)\n",
    "        y_preds.append(y_pred.detach().cpu().data.numpy())\n",
    "        \n",
    "    y_vals = torch.stack(y_vals,0).numpy()\n",
    "    y_vals = np.array(y_vals).reshape([-1,1])\n",
    "    y_vals_onehot = np.eye(10)[y_vals].reshape([-1,10])\n",
    "    y_preds = np.array(y_preds).reshape([-1,1])\n",
    "    y_outputs = np.array(y_outputs).reshape([-1,10])\n",
    "    print(metrics.accuracy_score(y_vals,y_preds))\n",
    "    print(metrics.f1_score(y_vals,y_preds,average=None))\n",
    "    print(metrics.roc_auc_score(y_vals_onehot,y_outputs,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848\n",
      "[0.98528666 0.99164835 0.98742747 0.98422091 0.98729029 0.98378983\n",
      " 0.98591549 0.98242188 0.98303342 0.97590361]\n",
      "[0.99991923 0.99997287 0.999894   0.99987015 0.99992592 0.99984971\n",
      " 0.99989979 0.99971084 0.99986771 0.99972332]\n"
     ]
    }
   ],
   "source": [
    "y_te = test_dataset.targets.numpy()\n",
    "LOG_DIR = 'Logs/'\n",
    "SAVE_DIR = 'Models/'\n",
    "\n",
    "SEED = 0\n",
    "best_save_path = SAVE_DIR + \"MNIST_CNN_Val_SEED_%d_model\"%SEED\n",
    "model = LeNet5().double().to(device)\n",
    "model.load_state_dict(torch.load(best_save_path)['net'])\n",
    "y_vals = []\n",
    "y_vals_onehot = []\n",
    "y_outputs = []\n",
    "y_preds = []\n",
    "for idx, (val_x, val_label) in enumerate(test_loader):\n",
    "    val_x, val_label = val_x.double().to(device), val_label.to(device)\n",
    "    y_vals.append(val_label.cpu().data)\n",
    "    y_vals_onehot.append(TF.one_hot(val_label.cpu().data,10).numpy())\n",
    "    outputs = model(val_x).detach()\n",
    "    y_output = TF.softmax(outputs,-1)\n",
    "    y_outputs.append(y_output.detach().cpu().data.numpy())\n",
    "    y_pred = torch.argmax(outputs, axis=-1)\n",
    "    y_preds.append(y_pred.detach().cpu().data.numpy())\n",
    "\n",
    "y_vals = torch.stack(y_vals,0).numpy()\n",
    "y_vals = np.array(y_vals).reshape([-1,1])\n",
    "y_vals_onehot = np.eye(10)[y_vals].reshape([-1,10])\n",
    "y_preds = np.array(y_preds).reshape([-1,1])\n",
    "y_outputs = np.array(y_outputs).reshape([-1,10])\n",
    "print(metrics.accuracy_score(y_vals,y_preds))\n",
    "print(metrics.f1_score(y_vals,y_preds,average=None))\n",
    "print(metrics.roc_auc_score(y_vals_onehot,y_outputs,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
