{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import mnist, CIFAR10\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import metrics\n",
    "import xgboost\n",
    "\n",
    "import time\n",
    "import torch.nn.functional as TF\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "test_transform = transforms.Compose([transforms.Resize((28,28)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "\n",
    "train_dataset = mnist.MNIST(root='data/MNIST/train', train=True,\n",
    "                              download=True,transform=transform)\n",
    "test_dataset = mnist.MNIST(root='data/MNIST/test', train=False,\n",
    "                             download=True, transform=test_transform)\n",
    "\n",
    "x_tr = train_dataset.data.numpy()\n",
    "y_tr = train_dataset.targets.numpy()\n",
    "x_tr = x_tr.reshape((-1, 28*28))\n",
    "\n",
    "x_te = test_dataset.data.numpy()\n",
    "y_te = test_dataset.targets.numpy()\n",
    "x_te = x_te.reshape((-1, 28*28))\n",
    "all_x = np.concatenate((x_tr,x_te),axis=0)\n",
    "all_y = np.concatenate((y_tr,y_te),axis=0)\n",
    "train_length = len(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "all_x_pca = pca.fit_transform(all_x)\n",
    "x_tr = all_x_pca[:train_length]\n",
    "x_te = all_x_pca[train_length:]\n",
    "\n",
    "print(x_tr.shape)\n",
    "print(x_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:05:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SEED:0,Accuracy Score:92.3833%\n",
      "[04:06:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SEED:1,Accuracy Score:92.5167%\n",
      "[04:06:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SEED:2,Accuracy Score:92.6000%\n",
      "[04:07:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SEED:3,Accuracy Score:91.7333%\n",
      "[04:07:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "SEED:4,Accuracy Score:92.0667%\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'Models/'\n",
    "for SEED in range(5):\n",
    "    np.random.seed(SEED)\n",
    "    all_index = np.arange(len(x_tr))\n",
    "    np.random.shuffle(all_index)\n",
    "    train_index = all_index[0:int(0.9*len(x_tr))]\n",
    "    val_index = all_index[int(0.9*len(x_tr)):]\n",
    "\n",
    "    train_x = x_tr[train_index]\n",
    "    train_y = y_tr[train_index]\n",
    "    val_x = x_tr[val_index]\n",
    "    val_y = y_tr[val_index]\n",
    "    # Train model\n",
    "    xgb_clf = xgboost.XGBClassifier(use_label_encoder=False)\n",
    "#     xgb_clf = xgboost.XGBClassifier(use_label_encoder=False,n_estimators=100,max_depth=25,max_leaves=30,learning_rate=0.01)\n",
    "    xgb_clf.fit(train_x, train_y)\n",
    "    # Save model\n",
    "    save_path = SAVE_DIR + 'MNIST_XGBoost_SEED_%d.pkl'%SEED\n",
    "    pickle.dump(xgb_clf, open(save_path, 'wb'))\n",
    "    # Load model\n",
    "    xgb_val_clf = pickle.load(open(save_path, 'rb'))\n",
    "    \n",
    "    y_pred = xgb_val_clf.predict(val_x)\n",
    "    score = metrics.accuracy_score(val_y, y_pred)\n",
    "    print('SEED:%d,Accuracy Score:%.4f%%'%(SEED,100*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED:0\n",
      "Accuracy Score: 0.9238333333333333\n",
      "F1 Score: 0.9237992129953445\n",
      "ROC AUC Score: 0.9871481481481481\n",
      "Average score:0.9449\n",
      "SEED:1\n",
      "Accuracy Score: 0.9251666666666667\n",
      "F1 Score: 0.9251686430168448\n",
      "ROC AUC Score: 0.9865185185185186\n",
      "Average score:0.9456\n",
      "SEED:2\n",
      "Accuracy Score: 0.926\n",
      "F1 Score: 0.9259002526114295\n",
      "ROC AUC Score: 0.9864814814814814\n",
      "Average score:0.9461\n",
      "SEED:3\n",
      "Accuracy Score: 0.9173333333333333\n",
      "F1 Score: 0.9174651460380686\n",
      "ROC AUC Score: 0.984888888888889\n",
      "Average score:0.9399\n",
      "SEED:4\n",
      "Accuracy Score: 0.9206666666666666\n",
      "F1 Score: 0.9206766005158774\n",
      "ROC AUC Score: 0.9869259259259261\n",
      "Average score:0.9428\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'Models/'\n",
    "for SEED in range(5):\n",
    "    np.random.seed(SEED)\n",
    "    all_index = np.arange(len(x_tr))\n",
    "    np.random.shuffle(all_index)\n",
    "    train_index = all_index[0:int(0.9*len(x_tr))]\n",
    "    val_index = all_index[int(0.9*len(x_tr)):]\n",
    "\n",
    "    train_x = x_tr[train_index]\n",
    "    train_y = y_tr[train_index]\n",
    "    val_x = x_tr[val_index]\n",
    "    val_y = y_tr[val_index]\n",
    "    val_y_onehot = np.eye(10)[val_y]\n",
    "\n",
    "    \n",
    "    save_path = SAVE_DIR + 'MNIST_XGBoost_SEED_%d.pkl'%SEED\n",
    "    \n",
    "    xgb_val_clf = pickle.load(open(save_path, 'rb'))\n",
    "    \n",
    "    y_pred = xgb_val_clf.predict(val_x)\n",
    "    y_prob = xgb_val_clf.predict_proba(val_x)\n",
    "    \n",
    "    score = metrics.accuracy_score(val_y, y_pred)\n",
    "    F1_score = metrics.f1_score(val_y, y_pred, average='weighted')\n",
    "    ROC_AUC_score = metrics.roc_auc_score(val_y_onehot, y_prob,average='samples'XGBoost)\n",
    "    print('SEED:%d'%(SEED))\n",
    "    print('Accuracy Score:', score)\n",
    "    print('F1 Score:', F1_score)\n",
    "    print('ROC AUC Score:', ROC_AUC_score)\n",
    "    print('Average score:%.4f'%((score+F1_score+ROC_AUC_score)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED:2\n",
      "Accuracy Score: 0.9237\n",
      "F1 Score: 0.9236704964124014\n",
      "ROC AUC Score: 0.9957977542440413\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = 'Models/'\n",
    "SEED = 2\n",
    "\n",
    "y_te_onehot = np.eye(10)[y_te]\n",
    "save_path = SAVE_DIR + 'MNIST_XGBoost_SEED_%d.pkl'%SEED\n",
    "\n",
    "xgb_val_clf = pickle.load(open(save_path, 'rb'))\n",
    "\n",
    "y_pred = xgb_val_clf.predict(x_te)\n",
    "y_prob = xgb_val_clf.predict_proba(x_te)\n",
    "\n",
    "score = metrics.accuracy_score(y_te, y_pred)\n",
    "F1_score = metrics.f1_score(y_te, y_pred, average='weighted')\n",
    "ROC_AUC_score = metrics.roc_auc_score(y_te_onehot, y_prob,multi_class='ovo')\n",
    "print('SEED:%d'%(SEED))\n",
    "print('Accuracy Score:', score)\n",
    "print('F1 Score:', F1_score)\n",
    "print('ROC AUC Score:', ROC_AUC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
